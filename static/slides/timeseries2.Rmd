---
title: "IM532 3.0 Applied Time Series Forecasting"
subtitle: "MSc in Industrial Mathematics"
author: "Dr. Thiyanga Talagala"
date: "8 March 2020"
output:
  xaringan::moon_reader:
    chakra: libs/remark-latest.min.js
    lib_dir: libs
    css: 
      - default
      - default-fonts
      - duke-blue
      - hygge-duke
      - libs/cc-fonts.css
      - libs/figure-captions.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

---

## Stochastic processes

"A statistical phenomenon that evolves in time according to probabilistic laws is called a stochastic process." (Box, George EP, et al. Time series analysis: forecasting and control.)

--
 
##  Non-deterministic time series or statistical time series

A sample realization from an infinite population of time series that could have been generated by a stochastic process. 

--

## Probabilistic time series model 

Let $\{X_1, X_2, ...\}$ be a sequence of random variables. Then the joint distribution of the random vector $[X_1, X_2, ..., X_n]'$ is 

$$P[X_1 \le x_1, X_2 \le x_2, ..., X_n \le x_n]$$
 

where $-\infty < x_1, ..., x_n < \infty$ and $n = 1, 2, ...$

---


## Mean function

--
The **mean function** of $\{X_t\}$ is

$$\mu_X(t)=E(X_t).$$
--
## Covariance function

The **covariance function** of $\{X_t\}$ is

$$\gamma_X(r, s)=Cov(X_r, X_s)=E[(X_r-\mu_X(r))(X_s-\mu_X(s))]$$

for all integers $r$ and $s$.

--

The covariance function of $\{X_t\}$ at lag $h$ is defined by
$$\gamma_X(h):=\gamma_X(h, 0)=\gamma(t+h, t)=Cov(X_{t+h}, X_t).$$

--

## Autocovariance function

The autocovariance function of ${X_t}$ at lag $h$ is

$$\gamma_X(h)=Cov(X_{t+h}, X_t).$$

---

## Autocorrelation function

The autocorrelation function of ${X_t}$ at lag $h$ is

$$\rho_X(h)=\frac{\gamma_X(h)}{\gamma_X(0)}=Cor(X_{t+h}, X_t).$$

---

## Weekly stationary

A time series $\{X_t\}$ is called weekly stationary if 

- $\mu_X(t)$ is independent of $t$.

- $\gamma_X(t+h, t)$ is independent of $t$ for each $h$.

--

## Strict stationarity of a time series

A time series $\{X_t\}$ is called weekly stationary if the random vector $[X_1, X_2..., X_n]'$ and $[X_{1+h}, X_{2+h}..., X_{n+h}]'$ have the same joint distribution for all integers $h$ and $n>0$.

---

# Simple time series models

## 1. iid noise

1. no trend or seasonal component

2. observations are independent and identically distributed (iid) random variables with zero mean. 

3. plays an important role as a building block for more complicated time series.

---------------------------------------------------------------------------------

$$P[X_1 \le x_1, X_2 \le x_2, ..., X_n \le x_n] = P[X_1 \le x_1]....P[X_n \le x_n].$$
--
Let $F_X(.)$ be the cumulative distribution function of each of the identically distributed random variables $X_1, X_2, ...$ Then, 
$$P[X_1 \le x_1, X_2 \le x_2, ..., X_n \le x_n] = F_X(x_1)...F_X(x_n)$$
--
There is no dependence between observations. Hence,
$$P[X_{n+h} \le x|X_1=x_1, ..., X_n=x_n] = P[X_{n+h} \le x].$$




---

All rights reserved by [Thiyanga S. Talagala](https://thiyanga.netlify.com/)
